{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9e69cec-aeaa-49d3-ab18-c18c50acceb4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'env'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lg/ftvnw2s97_z5h66qcl3vwwf00000gn/T/ipykernel_6133/1351158767.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwrangle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'env'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import env\n",
    "import wrangle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a67856b-f1fa-49b6-95e9-67d0ca8fa8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquire_zillow(use_cache=True):\n",
    "    \n",
    "    filename = ('zillow.csv')\n",
    "    if os.path.exists(filename) and use_cache:\n",
    "        print('Using CSV')\n",
    "        return pd.read_csv(filename)\n",
    "    \n",
    "    print('Acquiring from Database')\n",
    "    url = env.get_db_url('zillow')\n",
    "\n",
    "    zillow = pd.read_sql('''\n",
    "    SELECT *\n",
    "    FROM properties_2017\n",
    "    JOIN (SELECT parcelid as pid, MAX(transactiondate) as maxdate FROM predictions_2017 GROUP BY parcelid) as last_date\n",
    "    ON last_date.pid = parcelid\n",
    "    LEFT JOIN (SELECT parcelid as pid, transactiondate as maxdate, logerror FROM predictions_2017) as log\n",
    "    ON last_date.pid = log.pid AND last_date.maxdate = log.maxdate\n",
    "    LEFT JOIN propertylandusetype\n",
    "    USING(propertylandusetypeid)\n",
    "    LEFT JOIN storytype\n",
    "    USING(storytypeid)\n",
    "    LEFT JOIN typeconstructiontype\n",
    "    USING(typeconstructiontypeid)\n",
    "    LEFT JOIN airconditioningtype\n",
    "    USING(airconditioningtypeid)\n",
    "    LEFT JOIN architecturalstyletype\n",
    "    USING(architecturalstyletypeid)\n",
    "    LEFT JOIN buildingclasstype\n",
    "    USING(buildingclasstypeid)\n",
    "    LEFT JOIN heatingorsystemtype\n",
    "    USING(heatingorsystemtypeid)\n",
    "    ''',url)\n",
    "\n",
    "    print('Saving to CSV')\n",
    "    zillow.to_csv('zillow.csv',index=False)\n",
    "    return zillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd3ff1e-cc95-44ef-bccd-861a433a4962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e191a7ce-7412-4fc3-8038-94a07fb526a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_look(df):\n",
    "    print(f'Shape:\\n\\n{df.shape}\\n\\n')\n",
    "    print(f'Describe:\\n\\n{df.describe(include=\"all\")}\\n\\n')\n",
    "    print(f'Info:\\n\\n{df.info()}\\n\\n')\n",
    "    print(f'Histograms:\\n\\n{df.hist(figsize=(40,20), bins =20), plt.show()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5e2cd5-a67d-4bbc-b760-40b20fbbe68f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91a551e4-af55-4c11-ad9e-f6fb8d9b2882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_rows(df):\n",
    "    return pd.concat([\n",
    "           df.isna().sum().rename('count'),\n",
    "           df.isna().mean().rename('percent')\n",
    "           ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0701a214-b772-4745-826a-dbe1d46794db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59c29fdb-62fb-43e0-aceb-c900f723a26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_columns(df):\n",
    "    col_missing = pd.concat([\n",
    "    df.isna().sum(axis=1).rename('num_cols_missing'),\n",
    "    df.isna().mean(axis=1).rename('pct_cols_missing'),\n",
    "    ], axis=1).value_counts().sort_index()\n",
    "    col_missing = pd.DataFrame(col_missing)\n",
    "    col_missing.rename(columns={0:'num_rows'},inplace=True)\n",
    "    return col_missing.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fb82f7-5c5c-4a5e-b3a4-80521ced490f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32e3179d-9c80-476f-8e88-4cc0329ed000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df,required_col,required_row):\n",
    "    required_row = round(df.shape[1] * required_row)\n",
    "    required_col = round(df.shape[0] * required_col)\n",
    "    df.dropna(axis=0, thresh=required_row, inplace=True)\n",
    "    df.dropna(axis=1, thresh=required_col, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d78b58-7be2-48a2-a370-d5f07fe6fb4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d127d7f7-2360-43e0-9fa4-ec3134d81b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_zillow(df):\n",
    "    df.drop(columns=['id','pid','maxdate'],inplace=True)\n",
    "    df.dropna(subset=['latitude','longitude'],inplace=True)\n",
    "    df = df[df['propertylandusetypeid'].isin([260,261,263,264,266,267,269])]\n",
    "    df = df[~df['unitcnt'].isin([2.0,3.0,4.0,6.0])]\n",
    "    handle_missing_values(df,0.5,0.5)\n",
    "    df.dropna(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f478e9-d210-414f-abc3-c47cba7746bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbc3d18-35ec-48a8-9c36-70df6e975c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle_zillow(df,col,row):\n",
    "        \n",
    "        df = handle_missing_values(df,col,row)\n",
    "        df = cleanup_zillow(df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2d8f72-ee12-4dd9-b5a7-ac146d696752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe75e80-512f-4671-9b05-15cdb7a588cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, column_list):\n",
    "    ''' remove outliers from dataframe \n",
    "        then return the new dataframe\n",
    "    '''\n",
    "    # Iterate through column_list\n",
    "    for col in column_list:\n",
    "        \n",
    "        # find percentiles\n",
    "        q_25 = np.percentile(df[col], 25)\n",
    "        q_75 = np.percentile(df[col], 75)\n",
    "        \n",
    "        # Calculate IQR\n",
    "        iqr = q_75 - q_25\n",
    "        \n",
    "        # assign upper bound\n",
    "        upper_bound = q_75 + 1.5 * iqr   \n",
    "        \n",
    "        # assign lower bound \n",
    "        lower_bound = q_25 - 1.5 * iqr   \n",
    "\n",
    "        # assign df without outliers\n",
    "        df = df[(df[col] > lower_bound) & (df[col] < upper_bound)]\n",
    "        \n",
    "    # return dataframe without outliers    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa1295c-1d86-46f7-8ac2-df82519c48ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c5156d-8a7a-40b9-ada4-99f7d5e15b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df):\n",
    "    '''\n",
    "    This funciton splits the dataset for modeling into:\n",
    "    train - for exploring the data, and fitting the models\n",
    "    validate - for ensuring the model is not overfit\n",
    "    test - for testing the model on unseen data\n",
    "    '''\n",
    "    # This seperates out the test data from the train and validate data. Test makes up 20 % of the data.\n",
    "    train_validate, test = train_test_split(df, random_state=1729, test_size=0.2)\n",
    "    \n",
    "    # This seperates out the train and validates sets. Train makes up 56 % of the data and Validate makes up 24 %.\n",
    "    train, validate = train_test_split(train_validate, random_state=1729, test_size=0.3)\n",
    "    \n",
    "    # The funciton returns the split sets\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f90c5e9-9739-4d70-b381-e2411d2a80fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73f87d7-a7f5-4d83-92bb-66f812bc1041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_mall_cat(df):\n",
    "    dummy_name = pd.get_dummies(df[['gender']])\n",
    "    df = pd.concat([df,dummy_name],axis=1) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46bff30-3da0-4a32-9988-44cb6291c72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd80878-608c-4015-88db-9988b758a440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_mall(df):\n",
    "\n",
    "    col = ['age','annual_income','spending_score']\n",
    "\n",
    "    df_scaled = df[col]\n",
    "\n",
    "    minmax = MinMaxScaler()\n",
    "    minmax.fit(df[col])\n",
    "\n",
    "    df_scaled[col] = minmax.transform(df[col])\n",
    "    \n",
    "    return df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af03250b-03bc-4671-adc6-2e629cf8347f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab0bf44-1aec-4e53-9e55-30293b34e709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0179455e-5752-492a-b062-7288319bae82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
